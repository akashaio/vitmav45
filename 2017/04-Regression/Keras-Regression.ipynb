{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Copyright\n",
    "\n",
    "<PRE>\n",
    "Jelen iPython notebook a Budapesti Műszaki és Gazdaságtudományi Egyetemen tartott \"Deep Learning a gyakorlatban Python és LUA alapon\" tantárgy segédanyagaként készült. \n",
    "A tantárgy honlapja: http://smartlab.tmit.bme.hu/oktatas-deep-learning\n",
    "Deep Learning kutatás: http://smartlab.tmit.bme.hu/deep-learning\n",
    "\n",
    "A notebook bármely részének újra felhasználása, publikálása csak a szerzők írásos beleegyezése esetén megegengedett.\n",
    "\n",
    "2017 (c) Gyires-Tóth Bálint (toth.b kukac tmit pont bme pont hu)\n",
    "</PRE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Regresszió mély tanulással"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Ebben a notebookban a gépi tanulás egyik \"Hello world\"-jét fogjuk megismeri. Ehhez a Boston Housing Prices adatbázist fogjuk felhasználni. \n",
    "\n",
    "Az adatbázis formátumának leírását itt találjuk: https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.names\n",
    "Magát az adatbázist pedig innen tölthetjük le: https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data\n",
    "\n",
    "Töltsük le az utóbbi CSV fájlt és mentsük a jelenlegi Python forrás / notebook mellé.\n",
    "\n",
    "Következő lépésként importáljuk a szükséges modulokat és állítsunk be egy random seed-et:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "import copy\n",
    "import pandas as pd\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Ezután töltsük le és töltsük be az adatokat, válasszuk szét a train-validation-test adathalmazokat és standardizáljuk a bemeneteket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('housing.data', <http.client.HTTPMessage at 0x7fa32f337d68>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve (\"https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data\", \"housing.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"housing.data\", delim_whitespace=True, header=None)\n",
    "dataset = df.values\n",
    "test_split = 0.1\n",
    "valid_split = 0.2\n",
    "\n",
    "X = dataset[:,0:13]\n",
    "Y = dataset[:,13]\n",
    "\n",
    "v_length = int(X.shape[0]*(1-valid_split-test_split))\n",
    "t_length = int(X.shape[0]*(1-test_split))\n",
    "\n",
    "X_test = X[t_length:]\n",
    "Y_test = Y[t_length:]\n",
    "X_valid = X[v_length:t_length]\n",
    "Y_valid = Y[v_length:t_length]\n",
    "X = X[:v_length]\n",
    "Y = Y[:v_length]\n",
    "\n",
    "scaler = StandardScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Ezt követően adjuk meg a callback függvényeket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "patience=20\n",
    "early_stopping=EarlyStopping(patience=patience, verbose=1)\n",
    "checkpointer=ModelCheckpoint(filepath='weights.hdf5', save_best_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "És hozzuk létre a hálót és tanítsuk be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=13, units=100)`\n",
      "  \n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, activation=\"linear\")`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 354 samples, validate on 101 samples\n",
      "Epoch 1/1000\n",
      "Epoch 00000: val_loss improved from inf to 2238.04288, saving model to weights.hdf5\n",
      "1s - loss: 160.6470 - val_loss: 2238.0429\n",
      "Epoch 2/1000\n",
      "Epoch 00001: val_loss did not improve\n",
      "0s - loss: 43.9657 - val_loss: 3807.4827\n",
      "Epoch 3/1000\n",
      "Epoch 00002: val_loss did not improve\n",
      "0s - loss: 25.6695 - val_loss: 2289.2290\n",
      "Epoch 4/1000\n",
      "Epoch 00003: val_loss did not improve\n",
      "0s - loss: 25.3248 - val_loss: 2914.9482\n",
      "Epoch 5/1000\n",
      "Epoch 00004: val_loss did not improve\n",
      "0s - loss: 19.8369 - val_loss: 3750.2526\n",
      "Epoch 6/1000\n",
      "Epoch 00005: val_loss did not improve\n",
      "0s - loss: 19.5895 - val_loss: 3093.3275\n",
      "Epoch 7/1000\n",
      "Epoch 00006: val_loss did not improve\n",
      "0s - loss: 17.1458 - val_loss: 3032.7960\n",
      "Epoch 8/1000\n",
      "Epoch 00007: val_loss did not improve\n",
      "0s - loss: 21.1266 - val_loss: 4971.2608\n",
      "Epoch 9/1000\n",
      "Epoch 00008: val_loss did not improve\n",
      "0s - loss: 18.2996 - val_loss: 4268.2685\n",
      "Epoch 10/1000\n",
      "Epoch 00009: val_loss did not improve\n",
      "0s - loss: 19.5739 - val_loss: 3604.9762\n",
      "Epoch 11/1000\n",
      "Epoch 00010: val_loss did not improve\n",
      "0s - loss: 17.9368 - val_loss: 3392.6479\n",
      "Epoch 12/1000\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 15.5083 - val_loss: 3864.2866\n",
      "Epoch 13/1000\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 15.2840 - val_loss: 2605.6610\n",
      "Epoch 14/1000\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 16.8518 - val_loss: 3117.4699\n",
      "Epoch 15/1000\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 17.3994 - val_loss: 3190.5598\n",
      "Epoch 16/1000\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 13.8873 - val_loss: 3073.4780\n",
      "Epoch 17/1000\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 16.8706 - val_loss: 3277.9487\n",
      "Epoch 18/1000\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 10.6385 - val_loss: 4298.6994\n",
      "Epoch 19/1000\n",
      "Epoch 00018: val_loss improved from 2238.04288 to 1885.35242, saving model to weights.hdf5\n",
      "0s - loss: 12.3511 - val_loss: 1885.3524\n",
      "Epoch 20/1000\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 14.2811 - val_loss: 2221.7087\n",
      "Epoch 21/1000\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 12.0851 - val_loss: 3360.0815\n",
      "Epoch 22/1000\n",
      "Epoch 00021: val_loss did not improve\n",
      "0s - loss: 13.4092 - val_loss: 3129.4025\n",
      "Epoch 23/1000\n",
      "Epoch 00022: val_loss did not improve\n",
      "0s - loss: 12.6885 - val_loss: 2776.9686\n",
      "Epoch 24/1000\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 12.4620 - val_loss: 2407.1399\n",
      "Epoch 25/1000\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 13.0055 - val_loss: 1914.4989\n",
      "Epoch 26/1000\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 12.1339 - val_loss: 2909.1528\n",
      "Epoch 27/1000\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 11.1644 - val_loss: 2757.4663\n",
      "Epoch 28/1000\n",
      "Epoch 00027: val_loss did not improve\n",
      "0s - loss: 10.9734 - val_loss: 2009.0297\n",
      "Epoch 29/1000\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 12.4747 - val_loss: 2479.5357\n",
      "Epoch 30/1000\n",
      "Epoch 00029: val_loss improved from 1885.35242 to 1532.25922, saving model to weights.hdf5\n",
      "0s - loss: 14.8925 - val_loss: 1532.2592\n",
      "Epoch 31/1000\n",
      "Epoch 00030: val_loss improved from 1532.25922 to 879.92390, saving model to weights.hdf5\n",
      "0s - loss: 12.2765 - val_loss: 879.9239\n",
      "Epoch 32/1000\n",
      "Epoch 00031: val_loss did not improve\n",
      "0s - loss: 11.0742 - val_loss: 1583.5486\n",
      "Epoch 33/1000\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 10.2526 - val_loss: 1701.5266\n",
      "Epoch 34/1000\n",
      "Epoch 00033: val_loss did not improve\n",
      "0s - loss: 10.4332 - val_loss: 2642.6070\n",
      "Epoch 35/1000\n",
      "Epoch 00034: val_loss did not improve\n",
      "0s - loss: 9.4987 - val_loss: 3083.9315\n",
      "Epoch 36/1000\n",
      "Epoch 00035: val_loss did not improve\n",
      "0s - loss: 10.1344 - val_loss: 2952.5250\n",
      "Epoch 37/1000\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 11.7829 - val_loss: 2602.1721\n",
      "Epoch 38/1000\n",
      "Epoch 00037: val_loss did not improve\n",
      "0s - loss: 10.2774 - val_loss: 1726.9461\n",
      "Epoch 39/1000\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 10.2693 - val_loss: 1144.0900\n",
      "Epoch 40/1000\n",
      "Epoch 00039: val_loss did not improve\n",
      "0s - loss: 10.9451 - val_loss: 1924.3494\n",
      "Epoch 41/1000\n",
      "Epoch 00040: val_loss did not improve\n",
      "0s - loss: 11.0095 - val_loss: 1473.4871\n",
      "Epoch 42/1000\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 10.2831 - val_loss: 3003.6142\n",
      "Epoch 43/1000\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 9.9446 - val_loss: 2354.4362\n",
      "Epoch 44/1000\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 10.7315 - val_loss: 2322.1443\n",
      "Epoch 45/1000\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 8.2612 - val_loss: 3035.4479\n",
      "Epoch 46/1000\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 8.1967 - val_loss: 1659.0313\n",
      "Epoch 47/1000\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 9.7189 - val_loss: 1640.7450\n",
      "Epoch 48/1000\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 9.8919 - val_loss: 1785.3105\n",
      "Epoch 49/1000\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 10.7191 - val_loss: 2907.4808\n",
      "Epoch 50/1000\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 7.5749 - val_loss: 1703.6256\n",
      "Epoch 51/1000\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 8.0329 - val_loss: 1505.9193\n",
      "Epoch 52/1000\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 9.1279 - val_loss: 1117.4558\n",
      "Epoch 00051: early stopping\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(output_dim=100, input_dim=X.shape[1]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(output_dim=1, activation='linear'))\n",
    "\n",
    "sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='mse', optimizer=sgd)\n",
    "history=model.fit(X,Y,epochs=1000, \n",
    "                  batch_size=10,\n",
    "                  verbose=2,\n",
    "                  validation_data=(X_valid, Y_valid),\n",
    "                  callbacks=[checkpointer, early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "A tanítás végeztével visszatöltjük a legjobb modellt, és kiértékeljük ennek teljesítményét a teszt adatokon. Mit jelenthet ez az érték?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/51 [=================>............] - ETA: 0s\n",
      "Teszt hiba: 71.303842\n"
     ]
    }
   ],
   "source": [
    "model = load_model('weights.hdf5')\n",
    "\n",
    "test_err = model.evaluate(X_test, Y_test)\n",
    "print(\"\\nTeszt hiba: %f\" % (test_err))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
